# ğŸ¤– Assistente Virtual de Seguros de Vida com IA

Este projeto nasceu da vontade de unir tecnologia e experiÃªncia do dia a dia no setor de seguros. Atuando em uma seguradora de vida, percebi como a inteligÃªncia artificial pode ser uma aliada poderosa na hora de esclarecer dÃºvidas e melhorar o atendimento aos clientes.

Assim, surgiu a ideia de desenvolver um assistente virtual especializado em seguros de vida, utilizando IA local com o modelo Mistral via Ollama, sem dependÃªncia de serviÃ§os externos pagos.

O objetivo Ã© criar uma interface acessÃ­vel, capaz de responder com clareza e linguagem adequada Ã s principais dÃºvidas sobre esse tipo de seguro.

---

## ğŸ’¡ Funcionalidades

- Chat interativo com IA local (sem custos de API)
- Respostas geradas com base no modelo **Mistral** usando o **Ollama**
- Interface web simples e intuitiva
- Foco no tema â€œseguros de vidaâ€ com linguagem adaptada

---

## ğŸ› ï¸ Tecnologias Utilizadas

| Camada       | Tecnologia           |
| ------------ | -------------------- |
| Backend      | Go (Golang), Gin     |
| IA local     | Ollama + modelo Mistral |
| Frontend     | HTML, CSS, JavaScript |
| Versionamento| GitHub               |

---

## ğŸš€ Como rodar localmente

### 1. Instale o [Ollama](https://ollama.com/download)

Depois da instalaÃ§Ã£o, no terminal, execute:

```bash
ollama pull mistral
```
### 2. Rode o Servidor GO:

```bash
go run main.go
```
